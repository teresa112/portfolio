---
title: "World Bank Country Data Analysis Part 2"
output:
  html_notebook: default
  pdf_document: default
---
In the following we present the analysis for the world bank country data in R. The results are presented and interpreted in the report in more detail. 

Initiate packages & Set seed
```{r}
library(xlsx)
library(caret)
library(cluster)
library(NbClust)
library(stats)
library(dbscan)
library(factoextra)
library(magrittr)
library(FactoMineR)
library(fpc)

#MDS
library(stats)
library(cluster)
library(MASS)
library(smacof)

library(magrittr)
library(dplyr)
library(ggpubr)

#SOM
library(kohonen)

set.seed(123)
```

#Data Exploration


Import the data 
```{r}
#data
#SET YOUR WORKING DIRECTORY
countries_raw_na <- read.xlsx("Data.xlsx",1)
  
#the data has 192 observations and 54 variables
#but there are various columns in teh end of the data that are only NA 
#we remove all columns with only NA variables 
countries_raw <- countries_raw_na[ , ! apply( countries_raw_na , 2 , function(x) all(is.na(x)) ) ] 
head(countries_raw)

#renaming the columns 
names(countries_raw)[3:21]<- c("ForeignInvestment", "ElectricityAccess", "RenewableEnergy", "CO2Emission", "Inflation", "MobileSubscriptions", "InternetUse", "Exports", "Imports", "GDP", "MortalityMale", "MortalityFemale", "BirthRate", "DeathRate", "MortalityInfant", "LifeExpectancy", "FertilityRate", "PopulationGrowth", "UrbanPopulation")

#countrygroups
countrygroups_raw_na <- read.xlsx("Data.xlsx",2)

#we remove all columns with only NA variables 
countrygroups_raw <- countrygroups_raw_na[ , ! apply( countrygroups_raw_na , 2 , function(x) all(is.na(x)) ) ] 

#renaming the columns 
names(countrygroups_raw)[3:21]<- c("ForeignInvestment", "ElectricityAccess", "RenewableEnergy", "CO2Emission", "Inflation", "MobileSubscriptions", "InternetUse", "Exports", "Imports", "GDP", "MortalityMale", "MortalityFemale", "BirthRate", "DeathRate", "MortalityInfant", "LifeExpectancy", "FertilityRate", "PopulationGrowth", "UrbanPopulation")
head(countrygroups_raw)


#mapping of countries to classes 
mapping = read.xlsx("CLASS.xlsx", 2, header = TRUE)
head(mapping)

```


Identify rows with empty fields 
```{r}
#identify missing values 
sum(is.na(countries_raw)) #63 missing

#remove data that is missing more than 3 values
count_na <- apply(countries_raw, 1, function(z) sum(is.na(z)))
c_clean <- countries_raw[count_na < 4,]
nrow(c_clean)

#approximate missing values according to appropriate country group 
sum(is.na(c_clean)) #21 missing

for( i in 3:21){
  for( j in 1:183){
  if (is.na(c_clean[j,i])) {
    index<- which(as.character(c_clean$Country[j])==as.character(mapping$CountryCode))
    row<- mapping$GroupCode[index]
    myvalue<-0 
    trigger<-0
    
    for(x in 1:(length(row)-1)){
      tempval<-countrygroups_raw[which(as.character(countrygroups_raw$Country)==as.character(row[x])),i]
      if(is.na(tempval)){
          trigger<-trigger+1
      }else{
          myvalue<-myvalue+tempval
      }  
    }
    c_clean[j,i]<-myvalue/(length(row)-trigger-1)
    }
  }
}

head(c_clean)
str(c_clean)

sum(is.na(c_clean)) #0 missing 
rownames(c_clean)<-c_clean[,1] 

#c_clean is the unstandardized data 
```



Scaling & Center around 0
If we do not scale the data before we pursue PCA the varibale with the highest variance will automatically have the largest loading. Therefore we scale the data such that the standard deviation for each variable is 1 
```{r}
#boxplot data
boxplot(c_clean) #data has to be scaled otherwise GDP data get's way to much weight
#have a look without GDP: 
boxplot(c_clean[,c(2:11,13:21)]) #without GDP
#--> different scales 


# calculate the pre-process parameters from the dataset
c_scaled_ut <- preProcess(c_clean, method=c("center","scale")) 

# summarize transform parameters
print(c_scaled_ut)
# transform the dataset using the parameters
c_scaled <- predict(c_scaled_ut, c_clean)
# summarize the transformed dataset
summary(c_scaled)


countries <- c_scaled
variables <- countries[,3:21]

#row name
rownames(variables)<-countries[,1] 

#boxplot
boxplot(variables, main="Boxplot of scaled and centered data")

#variables is the standardized dataset with the country abbreviations as row names and the variables as columns

```


#Analysis

#Multi-Dimensional Scaling 

#Pearson

Metric MDS 

Distance Matrix
```{r}
pearson_dist <- get_dist(variables, stand=TRUE, method="pearson") 
#fviz_dist(pearson_dist, gradient=list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
pearson_matrix <- as.matrix(pearson_dist)
```

Hierarchical Clustering from Assignment 1 --> k=3
```{r}
#Linkage Ward2 
countries_hc_w <- hclust(d = pearson_dist, method = "ward.D2")
#d = dissimilarity structure 
#method agglomeration linkage: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median" or "centroid".

#Performance
#cophenetic - values >0.75
countries_coph <- cophenetic(countries_hc_w) 
cor(pearson_dist, countries_coph) #Correlation between cophenetic distance and the original distance
#[1] 0.8077969
countries_cor_w <- cor(pearson_dist, countries_coph)


#Create color vector for clusters
cutree.complete.p <- cutree(countries_hc_w, k=3)
clusvec.p <- cutree.complete.p
```


Classical Scaling 
```{r}
#mds
?cmdscale
classical.p <- cmdscale(pearson_dist)

#plot
plot(classical.p, xlab = "Dimension 1", ylab="Dimension 2", main = "Classical Scaling w/ k=3 Clusters")
colvec <- c("orange","blue","red", "green", "purple")
for (i in 1:length(classical.p[,1]))
  text (classical.p[i,1],classical.p[i,2],rownames(variables)[i],col=colvec[clusvec.p[i]],cex=0.85)
#legend = c("Developed Countries", "Emerging Markets", "Developing Countries", "Small State Outliers", "Arabian Outliers")


```

SMACOF
```{r}
#coefficient
smacof.p <- smacofSym(pearson_matrix, type = "ratio")

#plot
plot (smacof.p$conf, type="n", xlab="", ylab="", main="SMACOF Plot w/ k=5 and type='ratio'", xaxt="n", yaxt="n", asp=1)
#ensure you list enough colours for the number of clusters
for (i in 1:length(smacof.p$conf[,1]))
  text (smacof.p$conf[i,1],smacof.p$conf[i,2],rownames(variables)[i],col=colvec[clusvec.p[i]],cex=0.85)

#Shepard diagram
plot(smacof.p,"Shepard")

#stress
smacof.p$stress
#[1] 0.1700248
```

Non-metric MDS

SMACOF
```{r}
smacof.p.ord <- smacofSym(pearson_matrix, type = "ordinal")

#plot
plot (smacof.p.ord$conf, type="n", xlab="", ylab="", xaxt="n", yaxt="n", asp=1, main="SMACOF Plot w/ k=3 and type='ordinal'")
for (i in 1:length(smacof.p.ord$conf[,1]))
  text (smacof.p.ord$conf[i,1],smacof.p.ord$conf[i,2],rownames(variables)[i],col=colvec[clusvec.p[i]],cex=0.85)

#Shepard diagram 
plot(smacof.p.ord,"Shepard")

#stress
smacof.p.ord$stress
#[1] 0.1618221
```

Sammon
```{r}
sammon.p <- sammon(pearson_matrix)


#plot
plot (sammon.p$points, type="n", xlab="", ylab="", xaxt="n", yaxt="n", asp=1, main = "Sammon plot")
#ensure you list enough colours for the number of clusters
for (i in 1:length(sammon.p$points[,1]))
  text (sammon.p$points[i,1],sammon.p$points[i,2],rownames(variables)[i],col=colvec[clusvec.p[i]],cex=0.85)

#stress
sammon.p$stress
#0.04343816

```


Kruskals Method
```{r}
kruskal.p <- isoMDS(pearson_matrix)

#plot
plot (kruskal.p$points, type="n", xlab="", ylab="", xaxt="n", yaxt="n", asp=1, main = "Kruskal's plot")
for (i in 1:length(kruskal.p$points[,1]))
  text (kruskal.p$points[i,1],kruskal.p$points[i,2],rownames(variables)[i],col=colvec[clusvec.p[i]],cex=0.85)

#stress
kruskal.p$stress
#[1] 16.86172
```

#More Evaluation
```{r}
cmdscale(pearson_matrix, 1, eig=TRUE)$GOF
cmdscale(pearson_matrix, 2, eig=TRUE)$GOF
cmdscale(pearson_matrix, 3, eig=TRUE)$GOF

r <- cmdscale(pearson_matrix, eig=TRUE)
r$ac
plot(cumsum(r$eig) / sum(r$eig), 
       type="h", lwd=5, las=1, 
       xlab="Number of dimensions", 
       ylab=expression(R^2))
plot(r$eig, 
       type="h", lwd=5, las=1, 
       xlab="Number of dimensions", 
       ylab="Eigenvalues")

```


#Euclidean

Metric MDS 

Distance Matrix
```{r}
variables.dist.euc <- dist(variables)
variables.dist.matrix <- as.matrix(variables.dist.euc)
```

Classical Scaling 
```{r}
#clustering
clust.complete.euc <- hclust(variables.dist.euc, method = "complete")
cutree.complete.euc <- cutree(clust.complete.euc, k=3)
clusvec <- cutree.complete.euc

#mds
classical.euc <- cmdscale(variables.dist.euc)

#plot
plot(classical.euc, xlab = "Dimension 1", ylab="Dimension 2", main = "Classical Scaling w/ k=3 Clusters")
colvec <- c("green","blue","red", "orange", "purple")
for (i in 1:length(classical.euc[,1]))
  text (classical.euc[i,1],classical.euc[i,2],rownames(variables)[i],col=colvec[clusvec[i]],cex=0.85)
#legend = c("Developed Countries", "Emerging Markets", "Developing Countries", "Small State Outliers", "Arabian Outliers")
```

SMACOF
```{r}
#coefficient
smacof.euc <- smacofSym(variables.dist.matrix, type = "ratio")

#plot
plot (smacof.euc$conf, type="n", xlab="", ylab="", main="SMACOF Plot w/ k=3 and type='ratio'", xaxt="n", yaxt="n", asp=1)
#ensure you list enough colours for the number of clusters
for (i in 1:length(smacof.euc$conf[,1]))
  text (smacof.euc$conf[i,1],smacof.euc$conf[i,2],rownames(variables)[i],col=colvec[clusvec[i]],cex=0.85)

#Shepard diagram
plot(smacof.euc,"Shepard")
?Shepard

#stress value
smacof.euc$stress
#[1] 0.177363

```

Non-metric MDS

SMACOF
```{r}
smacof.euc.ord <- smacofSym(variables.dist.matrix, type = "ordinal")

# create empty plot
plot (smacof.euc.ord$conf, type="n", xlab="", ylab="", xaxt="n", yaxt="n", asp=1, main="SMACOF Plot w/ k=3 and type='ordinal'")
for (i in 1:length(smacof.euc.ord$conf[,1]))
  text (smacof.euc.ord$conf[i,1],smacof.euc.ord$conf[i,2],rownames(variables)[i],col=colvec[clusvec[i]],cex=0.85)

#stress
smacof.euc.ord$stress
#[1] 0.1100411
```

Sammon
```{r}
sammon.euc <- sammon(variables.dist.matrix)

# create empty plot
plot (sammon.euc$points, type="n", xlab="", ylab="", xaxt="n", yaxt="n", asp=1, main = "Sammon plot")
#ensure you list enough colours for the number of clusters

for (i in 1:length(sammon.euc$points[,1]))
  text (sammon.euc$points[i,1],sammon.euc$points[i,2],rownames(variables)[i],col=colvec[clusvec[i]],cex=0.85)

#stress
sammon.euc$stress
#[1] 0.08020821

```

Kruskals Method
```{r}
kruskal.euc <- isoMDS(variables.dist.matrix)

#plot
plot (kruskal.euc$points, type="n", xlab="", ylab="", xaxt="n", yaxt="n", asp=1, main = "Kruskal's plot")
for (i in 1:length(kruskal.euc$points[,1]))
  text (kruskal.euc$points[i,1],kruskal.euc$points[i,2],rownames(variables)[i],col=colvec[clusvec[i]],cex=0.85)

#stress
kruskal.euc$stress
#[1] 11.0211
```


#Self-organizing maps 

Variable matrix
```{r}
variablesmatrix
```


SOM Model
```{r}
#initiate grid
som_grid <- somgrid(xdim = 5, ydim=5, topo="hexagonal")

#model
som_model <- som(variablesmatrix,grid=som_grid, 
                 rlen=1000, 
                 alpha=c(0.05,0.01), 
                 keep.data = TRUE
                 )

#output structure
names(som_model)

#plot
plot(som_model, type="codes", palette.name = rainbow, codeRendering = "segments")
```

Training Process
```{r}
#plot
plot(som_model, type="changes")
```

Node Counts
```{r}
plot(som_model, type="counts")
```

U-Matrix 
```{r}
plot(som_model, type="dist.neighbours")
```

Codes
```{r}
plot(som_model, type="codes", codeRendering = "segments")
legend(x = mean(x$grid$pts[, 1]), xjust = 0.5, y = 0, yjust = 1,
```

Heatmaps 

```{r}
plotHeatMap <- function(som_model, data, variable=0){    
  # Plot a heatmap for any variable from the data set "data".
  # If variable is 0, an interactive window will be provided to choose the variable.
  # If not, the variable in "variable" will be plotted.
  
 
  interactive <- TRUE
  
  while (interactive == TRUE){
    
    if (variable == 0){
      #show interactive window.
      color_by_var <- select.list(names(data), multiple=FALSE,
                                  graphics=TRUE, 
                                  title="Choose variable to color map by.")
      # check for user finished.
      if (color_by_var == ""){ # if user presses Cancel - we quit function        
        return(TRUE)
      }
      interactive <- TRUE
      color_variable <- data.frame(data[, color_by_var])
          
    } else {
      color_variable <- data.frame(data[, variable])
      color_by_var <- names(data)[variable]
      interactive <- FALSE
    }
      
    #if the variable chosen is a string or factor - 
    #Get the levels and ask the user to choose which one they'd like.
    
    if (class(color_variable[,1]) %in% c("character", "factor", "logical")){
      #want to spread this out into dummy factors - but colour by one of those.
      temp_data <- dummy.data.frame(color_variable, sep="_")
      chosen_factor <- select.list(names(temp_data), 
                                   multiple=FALSE,
                                   graphics=TRUE, 
                                   title="Choose level of variable for colouring")
      color_variable <- temp_data[, chosen_factor]
      rm(temp_data, chosen_factor)
      color_by <- color_variable
    } else {      
      #impute the missing values with the mean.
      color_variable[is.na(color_variable[,1]),1] <- mean(color_variable[,1], na.rm=TRUE)
      #color_by <- capVector(color_variable[,1])
      #color_by <- scale(color_by)  
      color_by <- color_variable[,1]
    }
    unit_colors <- aggregate(color_by, by=list(som_model$unit.classif), FUN=mean, simplify=TRUE)
    plot(som_model, type = "property", property=unit_colors[,2], main=color_by_var, palette.name=coolBlueHotRed)    
  }
}

par(mfrow=c(4,5))
plotHeatMap(som_model, variables)
```

Quality plot
```{r}

plot(som_model,type="quality")
```


Mapping plot 
```{r}

plot(som_model,type="mapping")

```

Creating Clusters
```{r}
#head(som_model$unit.classif,15)

#table(som_model$unit.classif)

som.hc <- cutree(hclust(dist(som_model$codes[[1]])), 3)
plot(som_model, type="codes", codeRendering = "segments")
add.cluster.boundaries(som_model, som.hc)


##
plot(som_model, type="dist.neighbours", main = "SOM neighbour distances")
## use hierarchical clustering to cluster the codebook vectors
som.hc <- cutree(hclust(dist(som_model$codes[[1]])), 3)
add.cluster.boundaries(som_model, som.hc)

##
sommap <- som(pearson_matrix,grid = somgrid(3, 3, "rectangular"))
plot(sommap, type="dist.neighbours", main = "SOM neighbour distances")
## use hierarchical clustering to cluster the codebook vectors
som.hc <- cutree(hclust(dist(sommap$codes[[1]])), 3)
add.cluster.boundaries(sommap, som.hc)
```

#Evaluation
```{r}
#quantization error
mean(som_model$distances)

#unif-classification
som_model$unit.classif

```




























